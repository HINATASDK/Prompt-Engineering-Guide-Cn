# 杂项话题

在本节中，我们讨论提示工程中的其他杂项和未分类主题。它包括相对较新的想法和方法，随着它们被更广泛地采用，将最终被移入主要指南中。这部分指南也有助于了解最新的关于提示工程的研究论文。

**请注意，本节正在建设中。**

主题:

- [主动提示](#主动提示)
- [定向激励提示](#定向激励提示)
- [指导语言模型](#program-aided-language-models)
- [ReAct](#react)
- [多模态 Cot 提示](#多模态Cot提示)
- [图提示](#graphprompts)

---

## 主动提示

联想（CoT）方法依赖于一组人工注释的示例。问题在于，这些示例可能不是不同任务最有效的示例。为了解决这个问题，[Diao 等人，(2023)](https://arxiv.org/pdf/2302.12246.pdf)最近提出了一种新的提示方法，称为主动提示，可以将 LLM 调整到不同的特定任务示例提示（用人工设计的 CoT 推理注释）。

下面是这种方法的说明。第一步是查询 LLM，有时可以带上几个 CoT 的例子。*K*个可能的答案用于一组训练问题。基于*K*个答案计算不确定性指标(使用的是不一致)。选择最不确定的问题，由人类进行注释。然后使用新注释的例子来推断每个问题。

![](../img/active-prompt.png)

## 定向激励提示

Li 等(2023)提出了一种新的提示技术，以更好地指导 LLM 生成所需的摘要。

一个可调节的策略 LM 被训练来生成刺激/提示，参考用强化学习来优化 LLM。
下图展示了方向性刺激提示如何与标准提示相比。策略 LM 可以很小，并被优化以生成指导黑盒冻结 LLM 的提示。

![](../img/dsp.jpeg)

## Program-Aided Language Models

[Gao et al., (2022)](https://arxiv.org/abs/2211.10435) 提出了一种使用 大模型 阅读自然语言问题并生成程序作为中间推理步骤的方法。被称为程序辅助语言模型（PAL），它与思维提示的连锁提示不同，它不是使用自由形式的文本来获得解决方案，而是将解决方案步骤卸载到 Python 解释器等程序运行时中。

![](../img/pal.png)

即将推出完整示例！

---

## ReAct

[Yao et al., 2022](https://arxiv.org/abs/2210.03629) 在一个框架中引入了 大模型，以交叉的方式生成推理踪迹和特定任务的操作。生成推理踪迹可以使模型诱导、跟踪和更新操作计划，甚至处理异常情况。操作步骤可以与外部源（如知识库或环境）进行接口对接并收集信息。

ReAct 框架

ReAct 框架可以让 大模型 与外部工具进行交互，以获取更可靠和事实性的回应所需的额外信息。该框架已经被证明在自然语言理解任务（如机器理解和问答）中具有多个优势。

![](../img/react.png)

即将推出完整示例！

---

## 多模态 Cot 提示

[Zhang et al. (2023)](https://arxiv.org/abs/2302.00923) 提出了一种多模态链式思维提示方法。传统的 CoT 专注于语言模式。相比之下，多模态 CoT 将文本和视觉结合到一个两阶段框架中。第一步涉及基于多模态信息的基本原理生成。接下来是第二阶段，答案推理，利用信息丰富的生成基本原理。

多模态 CoT 模型（1B）在 ScienceQA 基准测试中优于 GPT-3.5。

![](../img/multimodal-cot.png)

---

## 图提示

[Liu et al., 2023](https://arxiv.org/abs/2302.08043) 提出了 GraphPrompt，这是一种新的图提示框架，可以提高下游任务的性能。

即将推出更多！

---

[上一节（对抗性提示）](https://www.prompting.work/post/5)
